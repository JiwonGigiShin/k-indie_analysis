{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4fb043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data                               \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#nlp\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# from nltk.stem import PorterStemmer\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# wordcloud\n",
    "from PIL import Image\n",
    "from wordcloud import STOPWORDS, WordCloud\n",
    "\n",
    "## translation\n",
    "# import googletrans\n",
    "# from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be05881",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ec6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #whole dataframe\n",
    "# def get_data(artist_id_input):\n",
    "#     total_df = pd.read_csv('data/indie_final_dataframe')\n",
    "#     df = total_df[total_df['artist_id']==int(artist_id_input)][['artist_name', 'song_name', 'year', 'lyrics']]\n",
    "#     return df\n",
    "\n",
    "# def basic_cleaning(artist_id):  \n",
    "#     df = get_data(artist_id)\n",
    "#     df['final_lyrics'] = df['Lyric'].apply(clean_text)\n",
    "#     df = df.groupby(['year']).sum()[['final_lyrics']]\n",
    "\n",
    "#     return df\n",
    "\n",
    "def clean_text(text):\n",
    "    stopwords_lst = list(set(stopwords.words('english')))\n",
    "    manual_sw = ['그','내','난','나는','나를','너를','너의','너와','더','내게','내가','oh','amp','im',\n",
    "                 '이렇게','이제','너는','니가','할','또','네가','na','수','날','아','게','그대','그대는',\n",
    "                 '널','네','것','더','건','그대의','언제나','다','이제는','그녀의','위해','같은','아','있는',\n",
    "                 '이','yeah','마','듯','니','youre','ye','ohh','두','eh','사이니까','will','오예','너무',\n",
    "                 '너랑','ah','좀','woo','자꾸','쉭','u','나의','s','아','네','안','la','으','거야','babe',\n",
    "                 '아아아아아','t','올','ya','gray','m','하지','돼','la','넌','너','그런','너에게','속에','엉',\n",
    "                 'woo','inside','부비대','정말','around','수도','u','꼭','두','1','우린','나','있어','너무나',\n",
    "                 '순','없는','아직도','마치','앞','항상','함께','않아','하지만','막','나에게','정말','다시','바로','싶어',\n",
    "                 '많은','어떻게','걸','one','없어','그대와','let','없잖어','아무것도','팡','아직','우리','을','를',\n",
    "                 '계속','아무','모두','모든','그것이','없는데','got','오예','당장','take','다른','나랑은','수많은',\n",
    "                 'll','해봐','멀리','그저','기덕','못','받거니','늘','않는','사는','주거니','해야','걸','아닌','이고',\n",
    "                 '못할','da','cha','asunder','이젠','손을','그렇게','해도','baby','해','tickin','수가','하고',\n",
    "                 'gon','go','say','때','것을','채','단','눈을','예','한','cream','christmas','merry','make',\n",
    "                 'know','her의','we는','눈이','볼','바바바','너에게ohh','people','give','90s','wan','하고','대로',\n",
    "                 '줄','잘','알','될','come','acdc','이런','raw','de','que','look''아아아','bye','있을','하는','저',\n",
    "                 '그렇게','쿵','참','말아라','chest에','님아','red','오오','모십니다','maker','우','어떤','we가',\n",
    "                 'waterfalls','tell','음악으로','풍문으로','build','don','talk','보여','say','blue','techno',\n",
    "                 'shoes','와','누가','되어','가는','고개','gim','들어','가지','we는','doo','alway','것만','tell',\n",
    "                 'bie','춤을','green','채팅','먹어','umm','대로','순간','know','그건','나와','cruise','coastal',\n",
    "                 'classic','playa','light','하는','see','그래','eye','time','비가','sun','hi','sun','surf',\n",
    "                 'ive','위에','달이','안엔','hey','지금','우','dive','cause','하나','see','know','에오','길을',\n",
    "                 '맞닿음','보고','될','음','아주','이유','나도','몇','surf', 'uh', '오',]\n",
    "    stopwords_lst.extend(manual_sw)\n",
    "    #changing to lowercase\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\r',' ')\n",
    "\n",
    "    # removing #´s \n",
    "    text = re.sub(r'#[A-Za-z0-9]+', ' ', text)\n",
    "    text = re.sub(r'#', ' ', text)\n",
    "\n",
    "    #indentation -> space\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '') \n",
    "\n",
    "    #strip\n",
    "    text = text.strip()\n",
    "\n",
    "    #tokenization\n",
    "    tokens = word_tokenize(text)   \n",
    "    filtered_words = [w for w in tokens if w not in stopwords_lst]\n",
    "    final = \" \".join(cat for cat in filtered_words)\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2fe4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/indie_final_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a3c1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "      <th>album_id</th>\n",
       "      <th>album</th>\n",
       "      <th>like_count</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>final_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>2275648</td>\n",
       "      <td>가슴 시린 이야기 (feat. 용준형 Of Beast)</td>\n",
       "      <td>677972</td>\n",
       "      <td>가슴 시린 이야기</td>\n",
       "      <td>[14,786]</td>\n",
       "      <td>[세상에 가장 예쁜 거짓말 goodbye goodbye\\r\\n가슴 찢겨도 뱉는 그 ...</td>\n",
       "      <td>2011-03-15</td>\n",
       "      <td>2011</td>\n",
       "      <td>세상에 가장 예쁜 거짓말 goodbye goodbye 가슴 찢겨도 뱉는 말 good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>2063982</td>\n",
       "      <td>결혼까지 생각했어</td>\n",
       "      <td>270770</td>\n",
       "      <td>Realslow Is Back</td>\n",
       "      <td>[18,843]</td>\n",
       "      <td>[To all My people hellow hellow hellow hellow ...</td>\n",
       "      <td>2010-08-26</td>\n",
       "      <td>2010</td>\n",
       "      <td>hellow hellow hellow hellow name realslow call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>2063984</td>\n",
       "      <td>사랑 그 몹쓸 병</td>\n",
       "      <td>270770</td>\n",
       "      <td>Realslow Is Back</td>\n",
       "      <td>[2,787]</td>\n",
       "      <td>[곁에 오지 말아요\\r\\n나를 보지 말아요\\r\\n단 한번 단 한번의 호흡조차 위험해...</td>\n",
       "      <td>2010-08-26</td>\n",
       "      <td>2010</td>\n",
       "      <td>곁에 오지 말아요 보지 말아요 한번 한번의 호흡조차 위험해 건네오는 인사에 스쳐가는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>1700206</td>\n",
       "      <td>Insomnia (불면증)</td>\n",
       "      <td>324617</td>\n",
       "      <td>Insomnia (불면증)</td>\n",
       "      <td>[41,145]</td>\n",
       "      <td>[내가 달리는 길은 Love, Love, Love, Love \\r\\n허나 그 길엔 ...</td>\n",
       "      <td>2009-02-18</td>\n",
       "      <td>2009</td>\n",
       "      <td>달리는 길은 love love love love 허나 길엔 온통 덫 덫 덫 덫 피할...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>3295630</td>\n",
       "      <td>Special Love</td>\n",
       "      <td>445300</td>\n",
       "      <td>Special Love</td>\n",
       "      <td>[2,157]</td>\n",
       "      <td>[대화 따위는 필요없어 \\r\\n서로 눈빛으로 모든 걸 알 수 있어 \\r\\n뭔가 흐름...</td>\n",
       "      <td>2013-11-29</td>\n",
       "      <td>2013</td>\n",
       "      <td>대화 따위는 필요없어 서로 눈빛으로 뭔가 흐름이 좋아 만남이 주는 기분에 취하고 황...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6653</td>\n",
       "      <td>가리온(Garion)</td>\n",
       "      <td>30503578</td>\n",
       "      <td>[19금]</td>\n",
       "      <td>20022222</td>\n",
       "      <td>금기어</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6653</td>\n",
       "      <td>가리온(Garion)</td>\n",
       "      <td>3325821</td>\n",
       "      <td>그래서 함께 하는 이유 2013 (inst.)</td>\n",
       "      <td>329757</td>\n",
       "      <td>가리온 15주년 기념 앨범 Instrumental</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2013-12-24</td>\n",
       "      <td>2013</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6653</td>\n",
       "      <td>가리온(Garion)</td>\n",
       "      <td>31200427</td>\n",
       "      <td>변</td>\n",
       "      <td>20055463</td>\n",
       "      <td>변</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[뭐 하냐고? 뭐 하냐고??\\r\\n(여보세요? 존나 랩해)\\r\\n가리온 퇴물랩 나이...</td>\n",
       "      <td>2018-08-23</td>\n",
       "      <td>2018</td>\n",
       "      <td>뭐 하냐고 뭐 하냐고 여보세요 존나 랩해 가리온 퇴물랩 나이만 처먹네 음원을 내봐도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6653</td>\n",
       "      <td>가리온(Garion)</td>\n",
       "      <td>32050291</td>\n",
       "      <td>그 놈의 음악 (Prod. Jinhu)</td>\n",
       "      <td>20036214</td>\n",
       "      <td>그 놈의 음악</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[비싼 건 손도 못 대던 시절\\r\\n먹고 살 수만 있어도 인정\\r\\n알바는 옵션이 ...</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>2020</td>\n",
       "      <td>비싼 손도 대던 시절 먹고 살 수만 있어도 인정 알바는 옵션이 기본 돈만 주면 뭐든...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6653</td>\n",
       "      <td>가리온(Garion)</td>\n",
       "      <td>2657612</td>\n",
       "      <td>꼴통 히어로</td>\n",
       "      <td>8000054</td>\n",
       "      <td>히어로 (OCN 드라마) OST</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[[나찰]\\r\\n스산한 밤거리 어딘지는 모른 채\\r\\n애타는 목소리가 누군가를 부를...</td>\n",
       "      <td>2012-05-16</td>\n",
       "      <td>2012</td>\n",
       "      <td>나찰 스산한 밤거리 어딘지는 모른 애타는 목소리가 누군가를 부를 어둠은 그렇듯 비명...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist_id   artist_name   song_id                       song_name  \\\n",
       "0       31236  휘성(Realslow)   2275648  가슴 시린 이야기 (feat. 용준형 Of Beast)   \n",
       "1       31236  휘성(Realslow)   2063982                       결혼까지 생각했어   \n",
       "2       31236  휘성(Realslow)   2063984                       사랑 그 몹쓸 병   \n",
       "3       31236  휘성(Realslow)   1700206                  Insomnia (불면증)   \n",
       "4       31236  휘성(Realslow)   3295630                    Special Love   \n",
       "..        ...           ...       ...                             ...   \n",
       "45       6653   가리온(Garion)  30503578                           [19금]   \n",
       "46       6653   가리온(Garion)   3325821       그래서 함께 하는 이유 2013 (inst.)   \n",
       "47       6653   가리온(Garion)  31200427                               변   \n",
       "48       6653   가리온(Garion)  32050291           그 놈의 음악 (Prod. Jinhu)   \n",
       "49       6653   가리온(Garion)   2657612                          꼴통 히어로   \n",
       "\n",
       "    album_id                        album like_count  \\\n",
       "0     677972                    가슴 시린 이야기   [14,786]   \n",
       "1     270770             Realslow Is Back   [18,843]   \n",
       "2     270770             Realslow Is Back    [2,787]   \n",
       "3     324617               Insomnia (불면증)   [41,145]   \n",
       "4     445300                 Special Love    [2,157]   \n",
       "..       ...                          ...        ...   \n",
       "45  20022222                          금기어       [16]   \n",
       "46    329757  가리온 15주년 기념 앨범 Instrumental        [1]   \n",
       "47  20055463                            변       [17]   \n",
       "48  20036214                      그 놈의 음악       [13]   \n",
       "49   8000054            히어로 (OCN 드라마) OST        [0]   \n",
       "\n",
       "                                               lyrics        date  year  \\\n",
       "0   [세상에 가장 예쁜 거짓말 goodbye goodbye\\r\\n가슴 찢겨도 뱉는 그 ...  2011-03-15  2011   \n",
       "1   [To all My people hellow hellow hellow hellow ...  2010-08-26  2010   \n",
       "2   [곁에 오지 말아요\\r\\n나를 보지 말아요\\r\\n단 한번 단 한번의 호흡조차 위험해...  2010-08-26  2010   \n",
       "3   [내가 달리는 길은 Love, Love, Love, Love \\r\\n허나 그 길엔 ...  2009-02-18  2009   \n",
       "4   [대화 따위는 필요없어 \\r\\n서로 눈빛으로 모든 걸 알 수 있어 \\r\\n뭔가 흐름...  2013-11-29  2013   \n",
       "..                                                ...         ...   ...   \n",
       "45                                                 []  2016-12-30  2016   \n",
       "46                                                 []  2013-12-24  2013   \n",
       "47  [뭐 하냐고? 뭐 하냐고??\\r\\n(여보세요? 존나 랩해)\\r\\n가리온 퇴물랩 나이...  2018-08-23  2018   \n",
       "48  [비싼 건 손도 못 대던 시절\\r\\n먹고 살 수만 있어도 인정\\r\\n알바는 옵션이 ...  2020-10-28  2020   \n",
       "49  [[나찰]\\r\\n스산한 밤거리 어딘지는 모른 채\\r\\n애타는 목소리가 누군가를 부를...  2012-05-16  2012   \n",
       "\n",
       "                                         final_lyrics  \n",
       "0   세상에 가장 예쁜 거짓말 goodbye goodbye 가슴 찢겨도 뱉는 말 good...  \n",
       "1   hellow hellow hellow hellow name realslow call...  \n",
       "2   곁에 오지 말아요 보지 말아요 한번 한번의 호흡조차 위험해 건네오는 인사에 스쳐가는...  \n",
       "3   달리는 길은 love love love love 허나 길엔 온통 덫 덫 덫 덫 피할...  \n",
       "4   대화 따위는 필요없어 서로 눈빛으로 뭔가 흐름이 좋아 만남이 주는 기분에 취하고 황...  \n",
       "..                                                ...  \n",
       "45                                                     \n",
       "46                                                     \n",
       "47  뭐 하냐고 뭐 하냐고 여보세요 존나 랩해 가리온 퇴물랩 나이만 처먹네 음원을 내봐도...  \n",
       "48  비싼 손도 대던 시절 먹고 살 수만 있어도 인정 알바는 옵션이 기본 돈만 주면 뭐든...  \n",
       "49  나찰 스산한 밤거리 어딘지는 모른 애타는 목소리가 누군가를 부를 어둠은 그렇듯 비명...  \n",
       "\n",
       "[6042 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['final_lyrics'] = df['lyrics'].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d37659a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>year</th>\n",
       "      <th>final_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>가슴 시린 이야기 (feat. 용준형 Of Beast)</td>\n",
       "      <td>2011</td>\n",
       "      <td>세상에 가장 예쁜 거짓말 goodbye goodbye 가슴 찢겨도 뱉는 말 good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>결혼까지 생각했어</td>\n",
       "      <td>2010</td>\n",
       "      <td>hellow hellow hellow hellow name realslow call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>사랑 그 몹쓸 병</td>\n",
       "      <td>2010</td>\n",
       "      <td>곁에 오지 말아요 보지 말아요 한번 한번의 호흡조차 위험해 건네오는 인사에 스쳐가는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>Insomnia (불면증)</td>\n",
       "      <td>2009</td>\n",
       "      <td>달리는 길은 love love love love 허나 길엔 온통 덫 덫 덫 덫 피할...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31236</td>\n",
       "      <td>휘성(Realslow)</td>\n",
       "      <td>Special Love</td>\n",
       "      <td>2013</td>\n",
       "      <td>대화 따위는 필요없어 서로 눈빛으로 뭔가 흐름이 좋아 만남이 주는 기분에 취하고 황...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id   artist_name                       song_name  year  \\\n",
       "0      31236  휘성(Realslow)  가슴 시린 이야기 (feat. 용준형 Of Beast)  2011   \n",
       "1      31236  휘성(Realslow)                       결혼까지 생각했어  2010   \n",
       "2      31236  휘성(Realslow)                       사랑 그 몹쓸 병  2010   \n",
       "3      31236  휘성(Realslow)                  Insomnia (불면증)  2009   \n",
       "4      31236  휘성(Realslow)                    Special Love  2013   \n",
       "\n",
       "                                        final_lyrics  \n",
       "0  세상에 가장 예쁜 거짓말 goodbye goodbye 가슴 찢겨도 뱉는 말 good...  \n",
       "1  hellow hellow hellow hellow name realslow call...  \n",
       "2  곁에 오지 말아요 보지 말아요 한번 한번의 호흡조차 위험해 건네오는 인사에 스쳐가는...  \n",
       "3  달리는 길은 love love love love 허나 길엔 온통 덫 덫 덫 덫 피할...  \n",
       "4  대화 따위는 필요없어 서로 눈빛으로 뭔가 흐름이 좋아 만남이 주는 기분에 취하고 황...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[['artist_id','artist_name', 'song_name', 'year', 'final_lyrics']]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63c277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('data/indie_final_df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b7fea",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d96327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by_year\n",
    "df_by_year = df_filtered.groupby('year')[['final_lyrics']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_year = df_by_year.loc[2008:]\n",
    "df_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 2000, ngram_range = (2,2)) #min_df = 0.01, max_df = 0.95,  ngram_range = (2,2)\n",
    "X = vectorizer.fit_transform(df_by_year['final_lyrics'])\n",
    "vectorized_ngram = pd.DataFrame(X.toarray(),\n",
    "columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = vectorized_ngram.transpose()\n",
    "new_df['sum'] = new_df.sum(axis=1)\n",
    "new_df = new_df.reset_index()\n",
    "\n",
    "# keywords = new_df[new_df['index'].str.contains(keyword_)]\n",
    "result = new_df[['index', 'sum']].sort_values(by='sum', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa4ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result[result['index'].str.contains('없이')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532fec52",
   "metadata": {},
   "source": [
    "## vectorizer by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b35e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c85faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer_by_year(yr):\n",
    "    df_year = df_filtered[df_filtered['year']==yr]\n",
    "    vectorizer = TfidfVectorizer(min_df = 0.01, max_df = 0.95, max_features = 50) #, ngram_range = (2,2)\n",
    "    X = vectorizer.fit_transform(df_year['final_lyrics'])\n",
    "    vectorized_ngram = pd.DataFrame(X.toarray(),\n",
    "    columns = vectorizer.get_feature_names_out())\n",
    "    \n",
    "    new_df = vectorized_ngram.transpose()\n",
    "    new_df['sum'] = round(new_df.sum(axis=1))\n",
    "    new_df = new_df.reset_index()\n",
    "\n",
    "    # keywords = new_df[new_df['index'].str.contains(keyword_)]\n",
    "    result = new_df[['index', 'sum']].sort_values(by='sum', ascending = False).reset_index(drop=True).rename(columns = {'index': 'word'})\n",
    "    result['year'] = yr\n",
    "    \n",
    "    return result[['year', 'word', 'sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbddbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_top50_words = []\n",
    "\n",
    "for yr in range(2008, 2024):\n",
    "    dataframe_top50_words.append(vectorizer_by_year(yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50words_df = pd.concat(dataframe_top50_words, axis=0)\n",
    "top50words_df.to_csv('keywords_by_year_vertically_concat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bacc44",
   "metadata": {},
   "source": [
    "# Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_year = df_by_year.loc[2000:]\n",
    "df_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c78f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_wordcloud_2(total):\n",
    "    \n",
    "    wordcloud = WordCloud(font_path = 'LINESeedKR-Rg.otf', width = 1000, height = 500, colormap='RdPu_r', \n",
    "                        max_words=150, background_color= 'white', collocations = False).generate(total)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "#     wordcloud.to_file(f\"final_wordcloud_png/{artist_id}_wordcloud.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4cca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_wordcloud(artist_id):\n",
    "    df = basic_cleaning(artist_id)\n",
    "    \n",
    "    total_lyrics = \" \".join(cat for cat in df.final_lyrics)\n",
    "    \n",
    "    wordcloud = WordCloud(font_path = 'LINESeedKR-Rg.otf', width = 1000, height = 500, colormap='RdPu_r', \n",
    "                        max_words=70, background_color= 'white', collocations = False).generate(total_lyrics)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "#     wordcloud.to_file(f\"final_wordcloud_png/{artist_id}_wordcloud.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1511e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud_by_year(artist_id):\n",
    "    \n",
    "    df = basic_cleaning(artist_id)\n",
    "    \n",
    "    def by_year(df):\n",
    "        lyrics_of_years = []\n",
    "        for i in range(len(df)):\n",
    "            one_year = \" \".join(cat for cat in df.iloc[i, :])\n",
    "            lyrics_of_years.append(one_year)\n",
    "        return lyrics_of_years\n",
    "\n",
    "\n",
    "    lyric_lst = by_year(df)\n",
    "    year_lst = [i for i in df.index]\n",
    "    \n",
    "    for lyric in lyric_lst:\n",
    "        word_cloud = WordCloud(font_path='Binggrae', width = 1000, height = 500, \n",
    "        colormap='BuPu', max_words=100, collocations = False).generate(lyric)\n",
    "\n",
    "        plt.figure(figsize = (10,8))\n",
    "        plt.imshow(word_cloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(year_lst[lyric_lst.index(lyric)])\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d6e8b6",
   "metadata": {},
   "source": [
    "## total wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "indie_total_df = pd.read_csv('data/indie_final_dataframe')\n",
    "indie_total_df = indie_total_df[['artist_x', 'artist_id', 'song_name', 'year', 'Lyric']]\n",
    "indie_total_df['final_lyrics'] = indie_total_df.Lyric.apply(clean_text)\n",
    "indie_total_df.drop(columns = ['Lyric'], inplace = True)\n",
    "indie_total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff670160",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lyrics = \" \".join(cat for cat in indie_total_df.final_lyrics)\n",
    "# total_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af02b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4318f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indie_temp = indie_total_df[['year', 'final_lyrics']]\n",
    "indie_by_year_df = indie_temp.groupby(['year']).sum()[['final_lyrics']]\n",
    "indie_by_year_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bffdab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indie_by_year_df = indie_by_year_df.loc[2008:]\n",
    "indie_by_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_by_year_2(df):\n",
    "    def by_year(df):\n",
    "        lyrics_of_years = []\n",
    "        for i in range(len(df)):\n",
    "            one_year = \" \".join(cat for cat in df.iloc[i, :])\n",
    "            lyrics_of_years.append(one_year)\n",
    "        return lyrics_of_years\n",
    "\n",
    "\n",
    "    lyric_lst = by_year(df)\n",
    "    year_lst = [i for i in df.index]\n",
    "\n",
    "    for lyric in lyric_lst:\n",
    "        word_cloud = WordCloud(font_path='Binggrae', width = 1000, height = 500, \n",
    "        colormap='BuPu', max_words=100, collocations = False).generate(lyric)\n",
    "\n",
    "        plt.figure(figsize = (10,8))\n",
    "        plt.imshow(word_cloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(year_lst[lyric_lst.index(lyric)])\n",
    "        plt.show()\n",
    "        \n",
    "        yearr=year_lst[lyric_lst.index(lyric)]\n",
    "        word_cloud.to_file(f\"data/final_wordcloud_png/{yearr}_wordcloud.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_by_year_2(indie_by_year_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e59421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "501a270e",
   "metadata": {},
   "source": [
    "# Topic Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3311a2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 18:53:46.171778: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc560790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/indie_final_df_cleaned.csv', index_col=0)\n",
    "df['final_lyrics'] = df.final_lyrics.astype('str')\n",
    "df = df.final_lyrics.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cef4aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Turn the list of string into a list of tokens\n",
    "df = [t.split() for t in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b000ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(df)\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8085d1f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('goodbye', 22),\n",
       "  ('rap안녕', 1),\n",
       "  ('가슴', 2),\n",
       "  ('가장', 1),\n",
       "  ('거짓말', 4),\n",
       "  ('결국', 1),\n",
       "  ('고마웠었어', 1),\n",
       "  ('괜찮아', 1),\n",
       "  ('그래도', 2),\n",
       "  ('그말', 1),\n",
       "  ('나만', 2),\n",
       "  ('남자로써', 1),\n",
       "  ('남자의', 2),\n",
       "  ('낳은', 1),\n",
       "  ('내사랑', 3),\n",
       "  ('누군가에게', 1),\n",
       "  ('느끼던', 1),\n",
       "  ('늘어난', 1),\n",
       "  ('더듬대며', 1),\n",
       "  ('동안', 1),\n",
       "  ('둘이서', 1),\n",
       "  ('드라마', 1),\n",
       "  ('리가', 1),\n",
       "  ('마지막', 1),\n",
       "  ('마지막으로', 1),\n",
       "  ('만나', 1),\n",
       "  ('만남', 1),\n",
       "  ('만든', 1),\n",
       "  ('만큼', 2),\n",
       "  ('말', 3),\n",
       "  ('말도', 1),\n",
       "  ('말이', 1),\n",
       "  ('맞추던', 1),\n",
       "  ('무겁게', 1),\n",
       "  ('미워도', 3),\n",
       "  ('미워서', 1),\n",
       "  ('믿었던', 1),\n",
       "  ('바보야', 1),\n",
       "  ('뱉는', 1),\n",
       "  ('버려진다', 1),\n",
       "  ('베낀다', 1),\n",
       "  ('보내는', 2),\n",
       "  ('보낼게', 1),\n",
       "  ('부모를', 1),\n",
       "  ('뺏긴다', 1),\n",
       "  ('뻔한', 1),\n",
       "  ('사람', 4),\n",
       "  ('사랑', 2),\n",
       "  ('사랑은', 1),\n",
       "  ('사랑을', 3),\n",
       "  ('사랑한', 1),\n",
       "  ('살아', 1),\n",
       "  ('세상에', 1),\n",
       "  ('속', 1),\n",
       "  ('슬퍼서', 1),\n",
       "  ('시린', 1),\n",
       "  ('아이처럼', 1),\n",
       "  ('아파', 4),\n",
       "  ('악물고', 1),\n",
       "  ('안고서', 1),\n",
       "  ('안녕', 3),\n",
       "  ('안녕이란', 1),\n",
       "  ('안녕이지', 1),\n",
       "  ('안되는', 1),\n",
       "  ('알려준', 3),\n",
       "  ('앞에', 1),\n",
       "  ('어떻게든', 2),\n",
       "  ('없잖아', 1),\n",
       "  ('예쁜', 1),\n",
       "  ('우리가', 1),\n",
       "  ('울지마', 1),\n",
       "  ('위한', 1),\n",
       "  ('위해서', 1),\n",
       "  ('이게', 1),\n",
       "  ('이를', 1),\n",
       "  ('이별', 2),\n",
       "  ('이별은', 1),\n",
       "  ('이별이잖아', 1),\n",
       "  ('이야기', 1),\n",
       "  ('잃은', 1),\n",
       "  ('입술도', 1),\n",
       "  ('잊을게', 1),\n",
       "  ('장면을', 1),\n",
       "  ('절망스러워', 1),\n",
       "  ('좋은', 3),\n",
       "  ('좋을', 1),\n",
       "  ('죄인이야', 1),\n",
       "  ('찢겨도', 1),\n",
       "  ('책임이야', 1),\n",
       "  ('처음이자', 1),\n",
       "  ('첫', 3),\n",
       "  ('체온도', 1),\n",
       "  ('추억', 1),\n",
       "  ('테잎처럼', 1),\n",
       "  ('해야하는', 1),\n",
       "  ('행복할게', 1),\n",
       "  ('행복해', 2),\n",
       "  ('힘껏', 1)]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[i], freq) for i, freq in doc] for doc in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06114501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.035*\"아니야\" + 0.032*\"어쩌면\" + 0.032*\"아니\" + 0.028*\"겨우\" + 0.028*\"그때\" + '\n",
      "  '0.026*\"말이야\" + 0.025*\"지나\" + 0.021*\"어\" + 0.019*\"안녕\" + 0.019*\"이야기\"'),\n",
      " (1,\n",
      "  '0.039*\"마음은\" + 0.033*\"지난\" + 0.030*\"걸음\" + 0.024*\"앉아\" + 0.020*\"꿈은\" + '\n",
      "  '0.016*\"버려\" + 0.015*\"집으로\" + 0.015*\"이유를\" + 0.015*\"좋아요\" + 0.014*\"돌아온\"'),\n",
      " (2,\n",
      "  '0.036*\"있다\" + 0.034*\"같이\" + 0.029*\"위\" + 0.025*\"모두가\" + 0.021*\"미친\" + '\n",
      "  '0.017*\"wait\" + 0.015*\"남겨진\" + 0.014*\"없인\" + 0.014*\"몸에\" + 0.013*\"걷던\"'),\n",
      " (3,\n",
      "  '0.072*\"그래서\" + 0.040*\"때까지\" + 0.036*\"가끔\" + 0.019*\"사람들이\" + 0.010*\"안아줘\" + '\n",
      "  '0.009*\"말들\" + 0.009*\"시작하는\" + 0.007*\"나갈\" + 0.006*\"살이\" + 0.005*\"안아줄\"'),\n",
      " (4,\n",
      "  '0.042*\"오직\" + 0.037*\"소리\" + 0.036*\"꿈을\" + 0.025*\"높이\" + 0.023*\"향해\" + 0.018*\"아래\" '\n",
      "  '+ 0.018*\"마음을\" + 0.017*\"바람\" + 0.017*\"않고\" + 0.016*\"생각이\"'),\n",
      " (5,\n",
      "  '0.050*\"’\" + 0.049*\"dont\" + 0.031*\"never\" + 0.031*\"like\" + 0.028*\"feel\" + '\n",
      "  '0.027*\"ill\" + 0.024*\"away\" + 0.020*\"day\" + 0.019*\"get\" + 0.018*\"back\"'),\n",
      " (6,\n",
      "  '0.050*\"그냥\" + 0.030*\"혼자\" + 0.027*\"그게\" + 0.027*\"가\" + 0.027*\"깊은\" + 0.019*\"먼저\" '\n",
      "  '+ 0.016*\"차라리\" + 0.016*\"버린\" + 0.014*\"뿐\" + 0.012*\"thats\"'),\n",
      " (7,\n",
      "  '0.144*\"love\" + 0.045*\"가진\" + 0.042*\"life\" + 0.027*\"us\" + 0.023*\"heart\" + '\n",
      "  '0.021*\"잊은\" + 0.019*\"먼\" + 0.019*\"삶의\" + 0.019*\"새로운\" + 0.017*\"keep\"'),\n",
      " (8,\n",
      "  '0.071*\"왜\" + 0.020*\"못한\" + 0.019*\"마음이\" + 0.018*\"것도\" + 0.017*\"않은\" + 0.016*\"진짜\" '\n",
      "  '+ 0.014*\"만나\" + 0.014*\"좋은\" + 0.014*\"아는\" + 0.013*\"점점\"'),\n",
      " (9,\n",
      "  '0.052*\"있네\" + 0.049*\"서\" + 0.026*\"아닌데\" + 0.024*\"돌아올\" + 0.021*\"간\" + '\n",
      "  '0.018*\"어디에\" + 0.013*\"누구\" + 0.012*\"떠올라\" + 0.012*\"없었던\" + 0.010*\"반\"'),\n",
      " (10,\n",
      "  '0.099*\"오\" + 0.062*\"결국\" + 0.028*\"만날\" + 0.017*\"동안\" + 0.016*\"한번도\" + 0.016*\"돈을\" '\n",
      "  '+ 0.014*\"하는지\" + 0.013*\"뛰는\" + 0.013*\"없어요\" + 0.013*\"마냥\"'),\n",
      " (11,\n",
      "  '0.092*\"좋아\" + 0.036*\"이대로\" + 0.031*\"아무런\" + 0.023*\"원래\" + 0.019*\"차\" + '\n",
      "  '0.018*\"있고\" + 0.018*\"느낄\" + 0.017*\"밤이면\" + 0.016*\"ooh\" + 0.014*\"그대가\"'),\n",
      " (12,\n",
      "  '0.043*\"작은\" + 0.022*\"노래\" + 0.020*\"것이\" + 0.020*\"위로\" + 0.019*\"사랑\" + 0.018*\"꿈\" '\n",
      "  '+ 0.018*\"세상\" + 0.017*\"속에서\" + 0.016*\"없네\" + 0.014*\"쉽게\"'),\n",
      " (13,\n",
      "  '0.020*\"속을\" + 0.020*\"몰라\" + 0.020*\"우리는\" + 0.016*\"알아\" + 0.016*\"어디로\" + '\n",
      "  '0.015*\"숨어\" + 0.015*\"줘\" + 0.015*\"아냐\" + 0.014*\"매일\" + 0.013*\"근데\"'),\n",
      " (14,\n",
      "  '0.070*\"밤\" + 0.043*\"오늘\" + 0.025*\"아름다운\" + 0.022*\"우릴\" + 0.021*\"이름\" + '\n",
      "  '0.017*\"멋진\" + 0.017*\"첫\" + 0.015*\"말해\" + 0.014*\"영원히\" + 0.013*\"만든\"'),\n",
      " (15,\n",
      "  '0.047*\"하늘\" + 0.036*\"야\" + 0.022*\"깊이\" + 0.019*\"등\" + 0.017*\"그러나\" + 0.016*\"일도\" '\n",
      "  '+ 0.015*\"여기서\" + 0.015*\"가네\" + 0.015*\"저기\" + 0.014*\"해서\"'),\n",
      " (16,\n",
      "  '0.034*\"해가\" + 0.023*\"믿고\" + 0.021*\"버렸어\" + 0.019*\"행복한\" + 0.015*\"불고\" + '\n",
      "  '0.012*\"뜻\" + 0.010*\"없었지\" + 0.009*\"물든\" + 0.007*\"녹아\" + 0.006*\"밤하늘\"'),\n",
      " (17,\n",
      "  '0.022*\"봐\" + 0.016*\"없이\" + 0.012*\"눈\" + 0.012*\"말\" + 0.009*\"여기\" + 0.009*\"같아\" + '\n",
      "  '0.009*\"마지막\" + 0.009*\"뭐\" + 0.008*\"갈\" + 0.008*\"길\"'),\n",
      " (18,\n",
      "  '0.026*\"몸을\" + 0.024*\"song\" + 0.022*\"보이는\" + 0.020*\"빈\" + 0.020*\"waiting\" + '\n",
      "  '0.020*\"사이\" + 0.019*\"matter\" + 0.019*\"sing\" + 0.019*\"하나가\" + 0.019*\"뜨거운\"'),\n",
      " (19,\n",
      "  '0.024*\"끝없이\" + 0.022*\"조금만\" + 0.020*\"높은\" + 0.019*\"잃어버린\" + 0.018*\"있지만\" + '\n",
      "  '0.016*\"밤에\" + 0.015*\"자리\" + 0.015*\"좋아하는\" + 0.013*\"들어와\" + 0.013*\"잡을\"')]\n"
     ]
    }
   ],
   "source": [
    "lda_model = LdaModel(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   num_topics=20,\n",
    "                   random_state=0,\n",
    "                   chunksize=100,\n",
    "                   alpha='auto',\n",
    "                   per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20ffa05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x13e3efb50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372bce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc1043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1b3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c711bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27dc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e7c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd9955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8dac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data = df_filtered.final_lyrics.values.tolist()\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e30f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73877ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
